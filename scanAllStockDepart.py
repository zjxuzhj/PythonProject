import logging
import os
import time
import pandas as pd
import getStockDepart


def setup_logger():
    logger = logging.getLogger('stock_analysis')
    if logger.handlers:  # å…³é”®åˆ¤æ–­ï¼šé¿å…é‡å¤é…ç½®
        return logger

    logger.setLevel(logging.DEBUG)
    logger.propagate = False  # å…³é—­å±‚çº§ä¼ æ’­

    # æ§åˆ¶å°Handlerï¼ˆä»…æ·»åŠ ä¸€æ¬¡ï¼‰
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s | %(levelname)-8s | %(message)s')
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    return logger


logger = setup_logger()


# è¿‡æ»¤åŒ—äº¤æ‰€å’ŒSTè‚¡ç¥¨
def filter_stocks(df):
    df['clean_code'] = df['stock_code'].str.extract(r'(\d{6})')[0]  # æå–çº¯æ•°å­—ä»£ç 
    is_bse = df['clean_code'].str.startswith(('43', '83', '87', '88', '92'))
    is_st = df['stock_name'].str.contains(r'ST|\*ST|é€€å¸‚', na=False)
    return df[~is_bse & ~is_st]


def save_temp(data, temp_file):
    """ä¸´æ—¶ä¿å­˜ï¼ˆæ— æ ¼å¼ï¼‰"""
    pd.DataFrame(data).to_excel(temp_file, index=False, engine='openpyxl')


def save_final(data, output_file, temp_file):
    """æœ€ç»ˆä¿å­˜ï¼ˆå¸¦æ ¼å¼ï¼‰"""
    result_df = pd.DataFrame(data)
    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:
        result_df.to_excel(writer, index=False, sheet_name='èƒŒç¦»ä¿¡å·')
        # åº”ç”¨æ ¼å¼è®¾ç½®...
    os.remove(temp_file)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶


# å¸¦é¢‘ç‡æ§åˆ¶çš„æ‰¹é‡å¤„ç†
def batch_process(stock_list, batch_size=1, delay=3, output_file='signals.xlsx'):
    temp_file = output_file.replace('.xlsx', '11_temp.xlsx')
    results = []

    # åŠ è½½å·²æœ‰è¿›åº¦
    try:
        existing_df = pd.read_excel(temp_file)
        results = existing_df.to_dict('records')
        logger.info(f"æ¢å¤å·²å¤„ç†æ•°æ®ï¼š{len(results)}æ¡")
    except FileNotFoundError:
        pass

    # åªæ˜¾ç¤ºåº•èƒŒç¦»çš„æ§åˆ¶å‚æ•°
    bd_signal = True
    # è·å–æ•°æ®çš„å¼€å§‹æ—¥æœŸ
    start_date = '20240201'
    # è·å–å½“å‰æ—¥æœŸï¼ˆå»é™¤æ—¶åˆ†ç§’ï¼‰
    current_date = pd.Timestamp.now().normalize()
    # è®¡ç®—æ—¶é—´çª—å£è¾¹ç•Œï¼Œ5å¤©å†…çš„ä¿¡å·
    signals_start_date = current_date - pd.Timedelta(days=30)
    signals_end_date = current_date

    total = len(stock_list)
    logger.info(f" å¼€å§‹æ‰¹é‡å¤„ç†ï¼Œå…±{total}åªè‚¡ç¥¨ï¼Œæ‰¹æ¬¡å¤§å°{batch_size}")

    # for i in range(0, 2000, batch_size):
    for i in range(0, len(stock_list), batch_size):
    # for i in range(1500, 1600, batch_size):
        batch = stock_list[i:i + batch_size]
        api_used = False  # æ‰¹æ¬¡APIä½¿ç”¨æ ‡è®°
        for code, name in batch:
            try:
                logger.info(f"âšª å¼€å§‹å¤„ç† {code} {name}")
                # è·å–æ•°æ®ï¼Œ# è·å–æ•°æ®åŠç¼“å­˜çŠ¶æ€
                df, is_cached = getStockDepart.get_stock_data(code, start_date)
                if not is_cached:
                    api_used = True  # æ ‡è®°æœ¬æ‰¹æ¬¡æœ‰APIè°ƒç”¨
                # æ·»åŠ å‡çº¿è®¡ç®—
                df = getStockDepart.calculate_moving_averages(df)
                # è®¡ç®—MACD
                macd_df = getStockDepart.calculate_macd(df)
                signals = getStockDepart.detect_divergence(code,macd_df,lookback=60, bd_signal=bd_signal)

                logger.debug(f"ğŸ” æ£€æµ‹åˆ°{len(signals)}æ¡ä¿¡å·")
                if not signals.empty:
                    # ç­›é€‰æ—¶é—´çª—å£å†…çš„ä¿¡å·
                    recent_signals = signals.loc[signals_start_date:signals_end_date]
                    logger.info(f"ğŸš© å‘ç°è¿‘5å¤©ä¿¡å·ï¼š{len(recent_signals)}æ¡ï¼ˆæ€»ä¿¡å·{len(signals)}æ¡ï¼‰")
                else:
                    recent_signals = pd.DataFrame()


                if not recent_signals.empty:
                    # åŠ¨æ€åˆ¤æ–­ä¿¡å·ç±»å‹
                    signal_type = None
                    if bd_signal:
                        if 'é¢„åº•' in recent_signals.columns and recent_signals['é¢„åº•'].any():
                            signal_type = 'é¢„åº•'
                    else:
                        if 'é¢„é¡¶' in recent_signals.columns and recent_signals['é¢„é¡¶'].any():
                            signal_type = 'é¢„é¡¶'
                        elif 'é¢„åº•' in recent_signals.columns and recent_signals['é¢„åº•'].any():
                            signal_type = 'é¢„åº•'

                    if signal_type:
                        results.append({
                            'ä»£ç ': code,
                            'åç§°': name,
                            'æœ€æ–°ä¿¡å·æ—¥æœŸ': recent_signals.index[-1].strftime('%Y-%m-%d'),
                            'ä¿¡å·ç±»å‹': signal_type,
                        })

            except Exception as e:
                logger.error(f"å¤„ç†{code}å‡ºé”™ï¼Œå·²ä¿å­˜å½“å‰è¿›åº¦ï¼Œé”™è¯¯ç±»å‹{e}")
                save_temp(results, temp_file)  # ç«‹å³ä¿å­˜
                raise

        # æ¯æ‰¹æ¬¡ä¿å­˜
        save_temp(results, temp_file)
        # æ ¹æ®APIä½¿ç”¨æƒ…å†µæ§åˆ¶é¢‘ç‡
        if api_used:
            time.sleep(delay)
    # æœ€ç»ˆä¿å­˜
    save_final(results, output_file, temp_file)
    return pd.DataFrame(results)


if __name__ == '__main__':
    setup_logger()
    # åŠ è½½è‚¡ç¥¨åˆ—è¡¨å¹¶è¿‡æ»¤
    all_stocks = pd.read_csv('stock_code_name.csv')
    filtered_stocks = filter_stocks(all_stocks)

    # åˆ†æ‰¹å¤„ç†
    result_df = batch_process(filtered_stocks[['stock_code', 'stock_name']].values)

    # æ ¼å¼åŒ–è¾“å‡º
    writer = pd.ExcelWriter('signals.xlsx', engine='xlsxwriter')
    result_df.to_excel(writer, index=False, sheet_name='èƒŒç¦»ä¿¡å·')

    # è®¾ç½®Excelæ ¼å¼
    workbook = writer.book
    format_red = workbook.add_format({'font_color': '#FF0000'})
    format_green = workbook.add_format({'font_color': '#00B050'})

    worksheet = writer.sheets['èƒŒç¦»ä¿¡å·']
    worksheet.conditional_format('D2:D1000', {
        'type': 'text',
        'criteria': 'containing',
        'value': 'é¡¶',
        'format': format_red
    })
    worksheet.conditional_format('D2:D1000', {
        'type': 'text',
        'criteria': 'containing',
        'value': 'åº•',
        'format': format_green
    })
    writer.close()
